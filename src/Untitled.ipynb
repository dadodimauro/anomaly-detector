{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f56f258-9297-43a9-b137-4ca702ef2ca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd /notebooks/anomaly-detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd1a76d2-139c-4451-b309-7e062d28ea7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "try:\n",
    "    from src.utils import utils\n",
    "    from src.utils import params\n",
    "    from src.utils import thresholds as th\n",
    "    from src.models import usad\n",
    "    from src.models import usad_utils\n",
    "    from src.data import columns\n",
    "    from src.data import preprocessing\n",
    "    from src.visualization import plotter\n",
    "except ModuleNotFoundError:\n",
    "    print(\"installing requirements..\")\n",
    "    os.system('pip install -r requirements.txt')\n",
    "    from src.utils import utils\n",
    "    from src.utils import params\n",
    "    from src.utils import thresholds as th\n",
    "    from src.models import usad\n",
    "    from src.models import usad_utils\n",
    "    from src.data import columns\n",
    "    from src.data import preprocessing\n",
    "    from src.visualization import plotter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5cfaf00-9bd6-41a0-b979-f5bc0a31cc35",
   "metadata": {},
   "outputs": [],
   "source": [
    "PREPROCESSING_PARAMS, TRAINING_PARAMS, INTERVALS_PARAMS, TH_ALGORITHM, PLOT_PARAMS, df_path = params.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4845fd6d-6e65-4513-b63e-a69f056ab2fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "class multivariate_ad():\n",
    "    def __init__(self, PREPROCESSING_PARAMS, TRAINING_PARAMS, INTERVALS_PARAMS, \n",
    "                         TH_ALGORITHM, PLOT_PARAMS, df_path):\n",
    "        \n",
    "        self.PREPROCESSING_PARAMS = PREPROCESSING_PARAMS\n",
    "        # self.TRAINING_PARAMS = TRAINING_PARAMS\n",
    "        self.INTERVALS_PARAMS = INTERVALS_PARAMS\n",
    "        self.TH_ALGORITHM = TH_ALGORITHM\n",
    "        self.PLOT_PARAMS\n",
    "        self.df_path = df_path\n",
    "        \n",
    "        self.batch_size = TRAINING_PARAMS['batch_size']\n",
    "        self.epochs = TRAINING_PARAMS['epochs']\n",
    "        self.hidden_size = TRAINING_PARAMS['hidden_size']\n",
    "        self.scaler = PREPROCESSING_PARAMS['normalization']\n",
    "        self.columns_name = PREPROCESSING_PARAMS['metrics']\n",
    "        self.alpha =  TRAINING_PARAMS['alpha']\n",
    "        self.beta =  TRAINING_PARAMS['beta']\n",
    "        \n",
    "        self.df = preprocessing.get_df(self.df_path, self.columns_name=columns_name)\n",
    "        self.w_size = windows_train.shape[1] * windows_train.shape[2]\n",
    "        self.z_size = windows_train.shape[1] * hidden_size\n",
    "        self.device = utils.get_default_device()\n",
    "\n",
    "        \n",
    "    # TODO: add fit and predict\n",
    "    def fit_predict(self, plot=True):\n",
    "        df_train, df_test, windows_train, windows_test, train_timestamps, test_timestamps = preprocessing.data_preprocessing(\n",
    "                                                                                                PREPROCESSING_PARAMS, df, \n",
    "                                                                                                INTERVALS_PARAMS=INTERVALS_PARAMS, \n",
    "                                                                                                scaler=scaler\n",
    "                                                                                            )\n",
    "        train_loader, val_loader, test_loader = preprocessing.get_dataloaders(\n",
    "                                                                    windows_train, windows_test, \n",
    "                                                                    batch_size, w_size, z_size\n",
    "                                                                )\n",
    "        # create model\n",
    "        model = usad.UsadModel(w_size, z_size)\n",
    "        model = utils.to_device(model, device)\n",
    "        history = usad_utils.training(epochs, model, device, train_loader, val_loader)\n",
    "        usad_utils.save_model(model)\n",
    "        model = usad_utils.load_checkpoint(model)\n",
    "        results = usad_utils.test_model(model, device, test_loader, alpha=self.alpha, beta=self.beta)\n",
    "        y_pred = usad_utils.get_prediction_score(results)\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        plotter.plot_history(history, save_static=PLOT_PARAMS['history_static'], save_html=PLOT_PARAMS['save_html'])\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
